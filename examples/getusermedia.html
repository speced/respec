<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/68a9e74">
  <link href="getusermedia.css" rel="stylesheet" type="text/css">

  <title>Media Capture and Streams</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <!--
   To publish this document, see instructions in README
   -->

   <script src='/node_modules/requirejs/require.js' data-main='/js/profile-w3c-common' async class='remove'></script>
  <script class="remove" src="getusermedia.js" type="text/javascript">
  <!-- keep this comment -->
  </script>
</head>

<body>
  <section id="abstract">
    <p>This document defines a set of JavaScript APIs that allow local media,
    including audio and video, to be requested from a platform.</p>
  </section>

  <section id="sotd">
    <p>This document is not complete. It is subject to major changes and, while
    early experimentations are encouraged, it is therefore not intended for
    implementation. The API is based on preliminary work done in the WHATWG.</p>
  </section>

  <section class="informative" id="intro">
    <h2>Introduction</h2>

    <p>Access to multimedia streams (video, audio, or both) from local devices
    (video cameras, microphones, Web cams) can have a number of uses, such as
    real-time communication, recording, and surveillance.</p>

    <p>This document defines the APIs used to get access to local devices that
    can generate multimedia stream data. This document also defines the MediaStream
    API by which JavaScript is able to manipulate the stream data or otherwise
    process it.</p>
  </section>

<section id="conformance">
      <p>
        This specification defines conformance criteria that apply to a single
        product: the <dfn>user agent</dfn> that implements the
        interfaces that it contains.
      </p>
      <p>
        Implementations that use ECMAScript to implement the APIs defined in
        this specification must implement them in a manner consistent with the
        ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]],
        as this specification uses that specification and terminology.
      </p>
    </section>
    <section>
      <h2>Terminology</h2>

      <dl>
        <dt><i>HTML Terms:</i></dt>
        <dd>
          <p>
            The <code><a href="http://dev.w3.org/html5/spec/webappapis.html#eventhandler">
            EventHandler</a></code> interface represents a callback used for event
            handlers as defined in [[!HTML5]].
          </p>
          <p>
            The concepts <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">
            queue a task</a></dfn> and
            <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">
            fires a simple event</a></dfn> are defined in [[!HTML5]].
          </p>

          <p>
            The terms <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handlers">
            event handlers</a></dfn> and
            <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">
            event handler event types</a></dfn> are defined in [[!HTML5]].
          </p>
        </dd>

        <dt><dfn>source</dfn></dt>
        <dd>
          <p>A source is the "thing" providing the source of a media stream
          track. The source is the broadcaster of the media itself. A
          source can be a physical webcam, microphone, local video or
          audio file from the user's hard drive, network resource, or
          static image.</p>

          <p>Some sources have an identifier which <em title="must"
          class="rfc2119">must</em> be unique to the application
          (un-guessable by another application) and persistent between
          application sessions (e.g., the identifier for a given
          source device/application must stay the same, but not be
          guessable by another application). Sources that must have an
          identifier are camera and microphone sources; local file
          sources are not required to have an identifier. Source
          identifiers let the application save, identify the
          availability of, and directly request specific sources.</p>

          <p>Other than the identifier, other bits of source identity
          are <strong>never</strong> directly available to the
          application until the user agent connects a source to a
          track. Once a source has been "released" to the application
          (either via a permissions UI, pre-configured allow-list, or
          some other release mechanism) the application will be able
          discover additional source-specific capabilities.</p>

          <p>Sources <strong>do not</strong> have constraints --
          tracks have constraints. When a source is connected to a
          track, it must conform to the constraints present on that
          track (or set of tracks).</p>

          <p>Sources will be released (un-attached) from a track when
          the track is ended for any reason.</p>

          <p>On the <code><a>MediaStreamTrack</a></code> object,
          sources are represented by a <code>sourceType</code>
          attribute. The behavior of APIs associated with the source's
          capabilities and state change depending on the source
          type.</p>

          <p>Sources have <code><a>capabilities</a></code>
          and <code><a>state</a></code>. The capabilities and state
          are "owned" by the source and are common to any (multiple)
          tracks that happen to be using the same source (e.g., if two
          different tracks objects bound to the same source ask for
          the same capability or state information, they will get back
          the same answer).</p>
        </dd>

        <dt><dfn data-lt="state">State (Source State)</dfn></dt>
        <dd>
          <p>State refers to the immediate, current value of the
          source's (optionally constrained) capabilities. State is
          always read-only.</p>
          <p>A source's state can change dynamically over time due to
          environmental conditions, sink configurations, or constraint
          changes. A source's state must always conform to the current
          set of mandatory constraints that all of the tracks it is
          bound to have defined, and should do its best to conform to
          the set of optional constraints specified.</p>
          <p>A source's state is directly exposed to audio and video
          track objects through individual read-only attributes. These
          attributes share the same name as their
          corresponding <a>capabilities</a>
          and <a>constraints</a>.</p>
          <p>Events are available that signal to the application that
          source state has changed.</p>
          <p>A conforming user-agent <em title="must"
          class="rfc2119">must</em> support all the state names
          defined in this spec.</p>
        </dd>

        <dt><dfn
        id="dfn-capabilities">Capabilities</dfn></dt>
        <dd>
          <p>Source capabilities are the intrinsic "features" of a
          source object. For each source state, there is a
          corresponding capability that describes whether it is
          supported by the source and if so, what the range of
          supported values are. Capabilities are expressed as either a
          series of states (for enumerated-type capabilities) or as a
          min/max range.</p>
          <p>The values of the supported capabilities must be
          normalized to the ranges and enumerated types defined in
          this specification.</p>
          <p>Capabilities return the same underlying per-source
          capabilities, regardless of any user-supplied constraints
          present on the source (capabilities are independent of
          constraints).</p>
          <p>Source capabilities are effectively
          constant. Applications should be able to depend on a
          specific source having the same capabilities for any
          session.</p>
        </dd>

        <dt><dfn
        id="dfn-constraints">Constraints</dfn></dt>

        <dd>
          <p>Constraints are an optional feature for restricting the
          range of allowed variability on a source. Without provided
          constraints, implementations are free to select a source's
          state from the full range of its supported capabilities, and
          to adjust that state at any time for any reason.</p>

          <p>Constraints may be optional or mandatory. Optional
          constraints are represented by an ordered list, mandatory
          constraints are an unordered set. The order of the optional
          constraints is from most important (at the head of the list)
          to least important (at the tail of the list).</p>

          <p>Constraints are stored on the track object, not the
          source. Each track can be optionally initialized with
          constraints, or constraints can be added afterward through
          the constraint APIs defined in this spec.</p>

          <p>Applying track level constraints to a source is
          conditional based on the type of source. For example,
          read-only sources will ignore any specified constraints on
          the track.</p>

          <p>It is possible for two tracks that share a unique source
          to apply contradictory constraints. Under such
          contradictions, the implementation will mute both tracks and
          notify them that they are over-constrained.</p>

          <p>Events are available that allow the application to know
          when constraints cannot be met by the user agent. These
          typically occur when the application applies constraints
          beyond the capability of a source, contradictory
          constraints, or in some cases when a source cannot sustain
          itself in over-constrained scenarios (overheating,
          etc.).</p>

          <p>Constraints that are intended for video sources will be
          ignored by audio sources and vice-versa. Similarly,
          constraints that are not recognized will be preserved in the
          constraint structure, but ignored by the UA. This
          will allow future constraints to be defined in a backward
          compatible manner.</p>

          <p>A correspondingly-named constraint exists for each
          corresponding source state name and capability name.  In
          general, user agents will have more flexibility to optimize
          the media streaming experience the fewer constraints are
          applied.</p>
        </dd>
      </dl>
    </section>


    <section>
      <h2>MediaStreamTrack</h2>

      <p>A <code><a>MediaStreamTrack</a></code> object represents a media
      source in the user agent. Several <code><a>MediaStreamTrack</a></code>
      objects can represent the same media source, e.g., when the user chooses
      the same camera in the UI shown by two consecutive calls to
      <code><a href="#dom-navigator-getusermedia">getUserMedia()</a></code>
      .</p>

      <p>Note that a web application can revoke all given permissions
      with <code><a href=
      "#dom-mediastreamtrack-stop">MediaStreamTrack.stop()</a></code>.</p>

      <section>
        <h3>Interface Definition</h3>

        <dl class="idl" title="interface MediaStreamTrack : EventTarget">

          <dt>readonly attribute DOMString kind</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-kind"><code>MediaStreamTrack.kind</code></dfn>
            attribute MUST return the string "<code>audio</code>" if the object
            represents an audio track or "<code>video</code>" if object represents
            a video track.</p>
          </dd>

          <dt>readonly attribute DOMString id</dt>

          <dd>
            <p>Unless a <code><a>MediaStreamTrack</a></code> object is created as
            a part a of special purpose algorithm that specifies how the track id
            must be initialized, the user agent MUST generate a globally unique
            identifier string and initialize the object's <code><a href=
            "#dom-mediastreamtrack-id">id</a></code> attribute to that string.</p>

            <p>An example of an algorithm that specifies how the track id must be
            initialized is the algorithm to represent an incoming network
            component with a <code><a>MediaStreamTrack</a></code> object.
            [[!WEBRTC10]]</p>

            <p><dfn id="dom-mediastreamtrack-id">
            <code>MediaStreamTrack.id</code></dfn> attribute MUST return the value
            to which it was initialized when the object was created.</p>
          </dd>

          <dt>readonly attribute DOMString label</dt>

          <dd>
            <p>User agents MAY label audio and video sources (e.g., "Internal
            microphone" or "External USB Webcam"). The <dfn id=
            "dom-mediastreamtrack-label"><code>MediaStreamTrack.label</code></dfn>
            attribute MUST return the label of the object's corresponding track,
            if any. If the corresponding track has or had no label, the attribute
            MUST instead return the empty string.</p>

            <p class="note">Thus the <code><a href=
            "#dom-mediastreamtrack-kind">kind</a></code> and <code title=
            "dom-MediaStreamTrack-label"><a href=
            "#dom-mediastreamtrack-label">label</a></code> attributes do not
            change value, even if the <code><a>MediaStreamTrack</a></code> object
            is disassociated from its corresponding track.</p>
          </dd>

          <dt>attribute boolean enabled</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-enabled"><code>MediaStreamTrack.enabled</code></dfn>
            attribute, on getting, MUST return the last value to which it was
            set. On setting, it MUST be set to the new value, and then, if the
            <code><a>MediaStreamTrack</a></code> object is still associated with
            a track, MUST enable the track if the new value is true, and disable
            it otherwise.</p>

            <p class="note">Thus, after a <code><a>MediaStreamTrack</a></code> is
            disassociated from its track, its <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute still
            changes value when set; it just doesn't do anything with that new
            value.</p>
          </dd>

          <dt>readonly attribute boolean muted</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-muted"><code>MediaStreamTrack.muted</code></dfn>
            attribute MUST return <code>true</code> if the track is <a href=
            "#track-muted">muted</a>, and <code>false</code> otherwise.</p>
          </dd>

          <dt>attribute EventHandler onmute</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-mute">mute</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>attribute EventHandler onunmute</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-unmute">unmute</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>readonly attribute boolean _readonly</dt>

          <dd>
            If the track (audio or video) is backed by a read-only
            source such as a file, or the track source is a local
            microphone or camera, but is shared so that constraints applied to
            the track cannot modify the source's state, the <dfn id=
            "dom-mediastreamtrack-readonly"><code>readonly</code></dfn>
            attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.
          </dd>

          <dt>readonly attribute boolean remote</dt>

          <dd>
            If the track is sourced by
            an <code>RTCPeerConnection</code>, the <dfn id=
            "dom-mediastreamtrack-remote"><code>remote</code></dfn>
            attribute MUST return the value <code>true</code>.
            Otherwise, it must return the value <code>false</code>.
          </dd>

          <dt>readonly attribute MediaStreamTrackState readyState</dt>

          <dd>
            <p>The <dfn id=
            "dom-mediastreamtrack-readystate"><code>readyState</code></dfn>
            attribute represents the state of the track. It MUST return the value
            to which the user agent last set it.</p>
          </dd>

          <dt>attribute EventHandler onstarted</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-started">started</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>attribute EventHandler onended</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-ended">ended</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>static void getSources(SourceInfoCallback resultCallback)</dt>

          <dd>
            <p>The static <dfn id="dom-mediastreamtrack-getsources">
            <code>getSources()</code></dfn> method collects authorized
            information for all available sources.</p>
          </dd>

          <dt>MediaTrackConstraints? constraints()</dt>

          <dd>
            Returns the complete constraints object associated with the
            track. If no mandatory constraints have been defined,
            the <code>mandatory</code> field will not be present (it will be
            undefined). If no optional constraints have been defined,
            the <code>optional</code> field will not be present (it will be
            undefined). If neither optional, nor mandatory constraints have been
            created, the value <code>null</code> is returned.
          </dd>

          <dt>MediaSourceStates states()</dt>

          <dd>
            Returns an object containing all the state variables
            associated with the allowed constraints.
          </dd>

          <dt>(AllVideoCapabilities or AllAudioCapabilities) capabilities ()</dt>

          <dd>
            <p>Returns a dictionary with all of the capabilities for the
            track type. If the track type is <code><a>VideoStreamTrack</a></code>,
            the <a><code>AllVideoCapabilities</code></a>
            dictionary is returned. If the track type
            is <code><a>AudioStreamTrack</a></code>,
            the <code><a>AllAudioCapabilities</a></code>
            dictionary is returned.</p>

            <p>Given that implementations of various hardware may not
            exactly map to the same range, an
            implementation <em title="should"
            class="rfc2119">should</em> make a reasonable attempt to
            translate and scale the hardware's setting onto the mapping
            provided by this specification. If this is not possible due
            to the user agent's inability to retrieve a given
            capability from a source, then for <a><code>CapabilityRange</code></a>-typed
            capabilities, the <code>min</code> and <code>max</code>
            fields will not be present on the returned dictionary, and
            the <code>supported</code> field will
            be <code>false</code>. For <code><a>CapabilityList</a></code>-typed
            capabilities, a suitable <code>"notavailable"</code> value
            will be the sole capability in the list.</p>

            <div class="note">
              <p>An example of the user agent providing an alternative
              mapping: if a source supports a hypothetical
              fluxCapacitance state whose type is a CapabilityRange, and
              the state is defined in this specification to be the range
              from -10 (min) to 10 (max), but the source's (hardware
              setting) for fluxCapacitance only supports values of "off"
              "medium" and "full", then the user agent should map the
              range value of -10 to "off", 10 should map to "full", and
              0 should map to "medium". Constraints imposing a strict
              value of 3 will cause the user agent to attempt to set the
              value of "medium" on the hardware, and return a
              fluxCapacitance <a>state</a> of 0, the closest supported
              setting. No error event is raised in this
              scenario.</p>
            </div>

            <p><code><a>CapabilityList</a></code> objects should order their enumerated
            values from minimum to maximum where it makes sense, or in
            the order defined by the enumerated type where
            applicable.</p>

            <p>See the <code><a>AllVideoCapabilities</a></code>
            and <code><a>AllAudioCapabilities</a></code>
            dictionaries for details on the expected types for the various
            supported state names.</p>
          </dd>

          <dt>void applyConstraints ()</dt>

          <dd>
            <dl class="parameters">
              <dt>MediaTrackConstraints constraints</dt>
              <dd>A new constraint structure to apply
                to this track.</dd>
            </dl>

            <p>This API will replace all existing constraints with the
            provided constraints (if existing constraints
            exist). Otherwise, it will apply the newly provided
            constraints to the track.</p>
          </dd>

          <dt>attribute EventHandler onoverconstrained</dt>

          <dd>This event handler, of type <code><a href=
          "#event-mediastreamtrack-overconstrained">overconstrained</a></code>, MUST be supported by
          all objects implementing the <code><a>MediaStreamTrack</a></code>
          interface.</dd>

          <dt>MediaStreamTrack clone()</dt>

          <dd>
            <p>Clones the given <code><a>MediaStreamTrack</a></code>.</p>

            <p>When the <dfn id=
            "dom-mediastreamtrack-clone"><code>clone()</code></dfn> method
            is invoked, the user agent MUST run the following steps:</p>

            <ol>
              <li>
                <p>Let <var>trackClone</var> be a newly constructed <code>
                <a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>Initialize <var>trackClone</var>'s <code><a href=
                "#dom-mediastreamtrack-id">id</a></code> attribute to a newly
                generated value.</p>
              </li>

              <li>
                <p>Let <var>trackClone</var> inherit this track's underlying
                source, <code>
                <a href="#dom-mediastreamtrack-kind">kind</a></code>, <code>
                <a href="#dom-mediastreamtrack-label">label</a></code> and
                <a href="#dom-mediastreamtrack-enabled">enabled</a></code>
                attributes.</p>
              </li>

              <li>
                <p>Return <var>trackClone</var>.</p>
              </li>
            </ol>
          </dd>

          <dt>void stop ()</dt>

          <dd>
            <p>When a <code><a>MediaStreamTrack</a></code>
            object's <dfn id=
            "dom-mediastreamtrack-stop"><code>stop()</code></dfn> method
            is invoked, the user agent MUST run following steps:</p>

            <ol>
              <li>
                <p>Let <var>track</var> be the current
                <code><a>MediaStreamTrack</a></code> object.</p>
              </li>

              <li>
                <p>If <var>track</var> has no source attached
                (<code>sourceType</code> is "none") or if the source is
                provided by an <code>RTCPeerConnection</code>, then abort these
                steps.</p>
              </li>

              <li>
                <p>Set <var>track's</var> <code><a href=
                "#dom-mediastreamtrack-readystate">readyState</a></code>
                attribute to <code>ended</code>.</p>
              </li>

              <li>
                <p>Permanently stop the generation of data for <var>track</var>'s
                source. If the data is being generated from a live source (e.g.,
                a microphone or camera), then the user agent SHOULD remove any
                active "on-air" indicator for that source. If the data is being
                generated from a prerecorded source (e.g. a video file), any
                remaining content in the file is ignored.</p>

                <p class="note">This will effectively
                <a href="#track-ended">end</a> all other
                <code><a>MediaStreamTrack</a></code> objects sharing the same
                source as <var>track</var>.</p>
              </li>
            </ol>

            <p>The task source for the <span title="concept-task">tasks</span>
            queued for the <code><a href=
            "#dom-mediastreamtrack-stop">stop()</a></code> method is the DOM
            manipulation task source.</p>
          </dd>
        </dl>

        <dl class='idl' title='enum MediaStreamTrackState'>
          <dt>new</dt>

          <dd>The track type is new and has not been initialized
            (connected to a source of any kind). This state implies that
            the track's label will be the empty string.</dd>

          <dt>live</dt>

          <dd>
            <p>The track is active (the track's underlying media source is making
            a best-effort attempt to provide data in real time).</p>

            <p>The output of a track in the <code>live</code> state can be
            switched on and off with the <code><a href=
            "#dom-mediastreamtrack-enabled">enabled</a></code> attribute.</p>
          </dd>

          <dt>ended</dt>

          <dd>
            <p>The track has <a href="#track-ended">ended</a> (the track's underlying media source is
            no longer providing data, and will never provide more data for this
            track).  Once a track enters this state, it never exits it.</p>

            <p>For example, a video track in a
            <code>MediaStream</code> ends if the user unplugs the
            USB web camera that acts as the track's media source.</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>Track Source Types</h2>

        <dl class="idl" title="enum SourceTypeEnum">

          <dt>none</dt>

	  <dd>This track has no source. This is the case when the
	  track is in the <code>"new"</code> or <code>"ended"</code>
	  <code><a>readyState</a></code>.</dd>

          <dt>camera</dt>

	  <dd>A valid source type only for
	  <code>VideoStreamTrack</code>s. The source is a local
	  video-producing camera source.</dd>

          <dt>microphone</dt>

	  <dd>A valid source type only for
	  <code>AudioStreamTrack</code>s. The source is a local
	  audio-producing microphone source.</dd>

        </dl>
      </section>

      <section>
        <h2>Source Info</h2>

        <dl class="idl" title=
        "callback SourceInfoCallback = void">
          <dt>sequence&lt;SourceInfo&gt; sourceInfoList</dt>

          <dd>A sequence of <code><a>SourceInfo</a></code> objects representing
          the result of a call to <code><a href=
          "#dom-mediastreamtrack-getsources"
          >MediaStreamTrack.getSources()</a></code>.</dd>
        </dl>

        <dl class="idl" title="dictionary SourceInfo">

          <dt>DOMString sourceId</dt>

          <dd>The unique id for this source as described in the
          <code><a>MediaSourceStates</a></code> dictionary.</dd>

          <dt>DOMString kind</dt>
          <dd>MUST be either "audio" or "video".</dd>

          <dt>DOMString label</dt>
          <dd>If the application is authorized to get info from this
          source, the <code>label</code> attribute will be filled in
          with exactly the same value as would have been returned from
          a call to <code><a>getUserMedia()</a></code> with a
          constraint specifying this
          source's <code><a>sourceId</a></code>.</dd>
        </dl>
      </section>

      <section>
        <h2>Video Facing Mode Enum</h2>

        <dl class="idl" title="enum VideoFacingModeEnum">
          <dt>user</dt>
          <dd>The source is facing toward the user (a self-view camera).</dd>

          <dt>environment</dt>
          <dd>The source is facing away from the user (viewing the
          environment).</dd>

          <dt>left</dt>
          <dd>The source is facing to the left of the user.</dd>

          <dt>right</dt>
          <dd>The source is facing to the right of the user.</dd>
        </dl>
      </section>

      <section>
        <h2>Isolated Media Streams</h2>

        <p>When either the "noaccess" or "peerIdentity" constraints is
          applied to a MediaStreamTrack, the track shall be isolated so that its
          content is not accessible to the content JS. An isolated media stream
          may be used for two purposes:
        </p>
        <ul>
          <li>
            <p>
              Displayed in an appropriate tag (e.g., a video or audio element).
              The video element MUST have a unique origin so that it is
              inaccessible to the content JS. This is the same security mechanism
              as is used with an ordinary audio or video element which has
              a src= property from a separate origin.
            </p>
          </li>
          <li>
            <p>
              Used as the argument to addStream() for a PeerConnection, subject
              to the restrictions detailed in the WebRTC document.
            </p>
          </li>
        </ul>
        <p>
          When the noaccess=true constraint applies to a track, that track
          may be added to any PeerConnection.
        </p>

        <p class="note"> Open Issue: The editors worry that the above paragraph
        is just wrong. If the track can be added to a PeerConnection that
        is connect to another PeerConenction in the same application, the
        application could get access to the data. We sugest this should be changed
        from "may be added" to "may not be added". This will allow noaccess=true
        to be used for things like hair check dialogs.
        </p>

        <p>
          When the peerIdentity=foo constraint applies to a track, then
          that track may be added only to PeerConnections with compatible
          peer identities as described in the WebRTC document.
        </p>

        <p>
          Both the noaccess and peerIdentity constraints must be mandatory.
          Any use of them in the optional block must trigger an error.
        </p>
      </section>
    </section>

</body>
</html>
